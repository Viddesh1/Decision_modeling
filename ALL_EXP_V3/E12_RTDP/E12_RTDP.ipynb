{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      " \n",
      "defaultdict(<function RTDP.calc_policy.<locals>.<lambda> at 0x000001FC70E48860>, {0: -3269.4303487248294, 20: -3268.650864422044, 1: -3269.804213892321, 21: -3269.490035687288, 2: -3270.806927816323, 41: 28.831525618161045, 22: -3270.4363880254195, 42: 30.0, 23: -3271.7328631729642, 40: 28.871108518445215, 3: -3272.144216943732, 61: 28.726295007686165, 60: 28.653230974425426, 81: 28.404280351816663, 62: 41.0, 80: 28.29804965688937, 100: -1173.206644783156, 101: -1162.929653685433, 82: 32.411381658562966, 102: -1132.490087563446, 83: 60.0, 122: -1341.13900674379, 103: -916.2068605885343, 123: -1675.4304942021572, 104: 60.0, 143: -1815.197640881998, 124: -1888.986746578832, 142: 37.0, 163: -1823.705989979966, 144: -1963.556447629739, 164: -1971.7966494624543, 145: -2040.8407177295146, 125: -2029.1719747469415, 165: -2020.627887309623, 146: -2076.3187127614697, 105: 20.664802478211115, 126: -2159.012033661436, 106: -2376.0645574839205, 127: 142.0, 86: -2503.125574280177, 107: -2466.614590074451, 66: -2357.954869318812, 85: 24.87070071284991, 87: -2777.1434754776983, 67: -2774.626582908286, 88: -3054.2759476385404, 47: 241.0, 68: -3190.7309492077507, 48: -3255.4741729939788, 69: -3264.4403512490935, 49: -3295.863670805165, 89: -3195.800607968328, 70: -3302.925265581001, 29: -3308.8109743216664, 50: -3314.9157594747167, 9: -3315.514065878305, 28: -3280.1430021136443, 30: -3315.3767006066255, 8: 26.0, 27: -3276.9460994045594, 43: 28.567571792227394, 24: -3273.015353288475, 4: -3273.523036334555, 5: -3274.583530283545, 25: -3274.148380414212, 6: -3275.3873307651397, 45: 242.0, 26: -3275.180805301202, 120: -1186.9814691980296, 140: 37.0, 121: -1220.6509123595047, 141: 27.923114025339707, 166: -2034.4922449533765, 147: -1839.0788125282284, 186: -2016.3756878326872, 167: -1911.8742101595185, 187: -2012.3392114781386, 168: -1815.1861712007121, 148: -1619.566915576549, 188: -1976.396275966802, 169: 111.0, 208: -2126.593739634011, 189: 17.0, 207: -2045.503160157065, 228: -2058.175165343855, 209: -2291.3851850697133, 229: -2456.527268168234, 210: -2302.5698928496845, 190: 16.291812006243198, 230: -2815.504675886478, 211: -1824.1949554593268, 170: 157.0, 191: 157.0, 7: -3275.922178243724, 46: -1796.4727314203067, 44: 28.284302385016375, 65: 33.0, 64: 29.155997055235925, 63: 32.00785628248777, 84: 32.68089000294423, 162: 16.58832177541408, 183: -1717.6367837639782, 184: -1938.5516569095412, 204: -1861.967408383938, 185: -1989.0326467061082, 205: -1949.7860584471305, 225: -1727.307620915056, 206: -2003.5413281050674, 226: 14.9730775180349, 246: 98.0, 227: 97.0, 224: -1698.857069450537, 245: -1537.854269310497, 244: -1510.4175430788723, 265: -1384.1684892429093, 10: -3323.1598842616545, 31: 22.0, 182: 14.48176341219975, 203: -1554.520953020431, 202: 14.375869824477336, 223: -1100.6171547550678, 222: -260.41706051061516, 243: -856.2802342814347, 221: -107.96655127143768, 242: -409.82251938307076, 201: 14.325046651726916, 220: 14.305749295302517, 241: -82.1612423723125, 200: 14.392451767373524, 240: 14.237269936022665, 260: 15.0, 261: -59.443210298508234, 262: -198.91399537089947, 282: -157.18275320759213, 263: 15.0, 281: 12.863684052952257, 90: -3269.1809925971775, 71: -3325.535561674565, 51: -3327.0745890461744, 52: -3341.203129877603, 32: -3341.0573151900435, 72: -3340.342848244343, 53: -3342.5628719648867, 92: -3334.6396631254497, 73: -3345.58683298996, 93: -3354.282376111342, 74: 21.0, 161: 19.697612115578586, 181: 14.364881199027666, 180: 14.395506990595793, 160: 28.0, 248: -1592.6755968396342, 247: -462.30872112313244, 268: 19.0, 249: -2268.4458640362864, 269: 9.177094214320558, 250: -2757.595779588956, 270: 15.0, 251: -3192.8295037478606, 231: -3233.898872700676, 128: -1230.139486483693, 149: -721.1680675847407, 129: 208.0, 150: -654.2372871776732, 109: 24.035145388510262, 110: 207.0, 91: -3309.6559251281647, 111: -2546.5774538392693, 33: -3341.4227013943732, 54: 22.0, 113: -3328.03383789212, 94: -3382.92133314412, 112: -3068.6484424621235, 133: 19.632314678183537, 114: -3562.4231375491127, 134: -3977.2802966780346, 115: 19.0, 264: -1384.9431984989926, 11: -3331.4591959762356, 12: -3340.8597368753844, 108: -2247.3837710226003, 130: -566.2760475765461, 151: -677.109540481835, 131: -1262.0143499920362, 132: 32.0, 95: -3232.550901133743, 75: -2888.370757784757, 96: -3426.759348242132, 76: -2891.096348477858, 116: -4157.682059365376, 97: 17.558176939203364, 56: -2359.153072283807, 77: 27.0, 36: -1644.3067749632971, 55: -2542.6788832142297, 57: 20.991960661840928, 35: -2380.861122975763, 117: -4179.369397704695, 98: 259.0, 137: -5260.393893695306, 118: -3122.0685310883114, 138: -5448.103270194855, 119: 259.0, 158: -5562.776687570828, 139: -5522.725521786471, 159: -5598.888460340993, 302: -113.41061250305307, 283: -284.6606955283367, 301: 12.59076927330189, 322: -30.208070956075233, 303: -194.85634169958004, 300: 16.0, 321: 12.851699287467948, 320: 14.0, 341: 15.0, 171: -121.00236660610084, 152: 55.07274084523792, 172: 1185.0, 13: -3340.9713884084235, 14: -3147.3408434277167, 34: -2955.9989749905167, 212: 62.0, 232: -3695.123806217391, 271: 10.4954691307289, 252: -3591.6187290528505, 272: -6.815548782341074, 253: -3897.1209724346477, 292: 4.13271874259389, 273: -5.037045429447431, 293: 0.9137050101227443, 274: 10.0, 313: -1.6701578901938414, 294: 11.0, 312: 34.0, 333: -3693.5396386109264, 314: 92.0, 284: -1277.0558411279749, 304: -1210.5312258116385, 285: -1269.8751115784075, 324: -1140.2507990381532, 305: -1238.5626380234362, 323: -333.88287833675315, 280: 13.847099824239042, 342: 11.809020596892053, 343: 10.551991397987925, 363: -169.46782462430028, 344: -976.4939265003458, 364: -501.0457381093402, 345: -1333.2176508515186, 384: 12.0, 365: -422.8774267855385, 153: 1185.0, 15: 1258.0, 16: -193.40430153120622, 37: 28.0, 17: 1258.0, 266: -810.2471495447256, 325: -1364.357614347578, 346: -1753.536188874478, 326: -1598.337256171228, 366: -19.276634059161854, 347: -2508.096517360292, 327: -2318.7876435093235, 367: -2663.2935396835305, 348: -2548.960438856888, 387: -2781.6986165466096, 368: -2706.330263012901, 388: -2909.2594006813406, 369: 9.362380475005468, 328: -2445.586409858304, 349: 29.0, 308: -2255.3515390739512, 329: -2471.7520676648323, 309: -2323.0177513884373, 330: -2656.159678481803, 286: -1170.7226753678103, 267: 98.0, 154: -3944.6143740049397, 135: -4425.214387141516, 174: -3426.752339374091, 155: -4430.1592363073205, 58: 18.37801826360402, 306: 15.0, 307: -2009.3934635425082, 287: -1463.4885612001717, 288: -1225.2807219799279, 289: 19.0, 136: -4868.753179822419, 157: -5465.276773740152, 156: -4921.07722979648, 177: -5573.407824590147, 176: 12.0, 173: -1915.5329908985386, 194: -4421.278926731086, 175: 17.0, 193: -3504.146633321525, 214: -4770.841280387243, 195: -4990.113268103552, 215: -5186.253839898032, 196: -5363.87232723292, 235: -5097.398384204295, 216: -5471.668385869715, 236: -5396.969382872251, 217: -5654.52592242233, 197: -5630.438195988381, 362: 14.0, 383: -78.29368705980943, 386: -52.95026441049583, 385: -187.34594156694592, 389: -3061.141162410427, 370: 29.0, 179: -5637.47815239293, 178: -5624.827092144291, 199: -5650.457155433438, 198: -5663.9159633232475, 218: -5711.244073297648, 238: -5815.6087507287575, 219: 9.0, 237: -5622.217642128823, 258: -6113.689671315254, 239: 7.0, 192: 17.1539232121924, 213: -4178.271006309669, 233: -4261.367252922599, 234: -4709.730090281837, 310: -2261.472936838978, 350: -693.4027500047823, 331: -3237.803246987393, 311: -1818.733849851776, 351: -3508.397282854437, 332: -3557.5526615373533, 352: -3749.194957309528, 372: -3767.9606726313914, 353: -3928.3347366261055, 371: -3549.6096898226883, 291: 34.0, 254: -3839.8501977756564, 255: -2914.7083072640376, 275: 187.0, 256: 187.0, 257: 8.0, 390: -3217.3271098403466, 391: -3379.9685825009637, 392: 8.0, 334: -3609.6581918246848, 290: 8.17105835836666, 38: 16.220168604157823, 78: 19.621508552327157, 59: 19.0, 79: 14.506137429949495, 382: 13.0, 278: -6290.522637776872, 259: -6235.7403911397, 277: -4436.743536044082, 298: -6399.838480273781, 279: -6358.485223505339, 297: -5647.072397374268, 318: -6482.536561870733, 299: -6426.907241238336, 319: -6454.362715724493, 317: -6109.883534671072, 338: -6594.628729780203, 316: -2620.388198253136, 337: -6201.849574277708, 296: 123.0, 315: -1872.116194569275, 336: 58.0, 373: -4006.384603818439, 354: -4032.875140072876, 393: 4.0, 374: -4323.216015644313, 276: -1375.8145120146942, 357: -5901.814712558552, 358: -7100.089773892786, 339: 2.0, 394: -4937.9797455308335, 375: 201.0, 355: -3848.9088544434426, 335: -3108.678650095892, 295: 91.0, 356: -4406.534423179199, 395: -5560.9734569418415, 376: -3470.0119114487793, 396: -6213.82120778191, 377: 201.0, 378: -7388.983372537723, 359: -7317.034299864426, 398: -7534.726900191272, 379: -7535.576410395515, 399: -7681.0, 397: -6872.474604672113, 18: 15.67850711305694, 39: 15.737497543428168, 19: 15.453034329471167, 99: 13.946014108806848})\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "0.4936\n"
     ]
    }
   ],
   "source": [
    "# Real Time Dynamic Programming (RTDP) Algorithm\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from gym.envs.toy_text.frozen_lake import FrozenLakeEnv\n",
    "\n",
    "\n",
    "MAP_20x20 = [\n",
    "    'SFFFFFFFHFFFFFFHFHFF',\n",
    "    'FFFFFFFFFFFHFFFFFHFF',\n",
    "    'FFHFFHFHFFFFFFHFFFFH',\n",
    "    'FFHFFHFFFFFFFFHFFHFF',\n",
    "    'FFFHFFFFFFFFFFFFFFHF',\n",
    "    'FFFFHFFFFFHFFFFHFFFH',\n",
    "    'FFFFFFFHFHFFHFFFFFFF',\n",
    "    'HFHFFFFFFFFFFHFFFFFF',\n",
    "    'HFFFFFFFFHHFHFFHHFFF',\n",
    "    'FFFFFFFFFHFHFFFFFFFF',\n",
    "    'FFFFFFFFFFFFHFFFFFFH',\n",
    "    'FFFFFFFHFFFFFFFFFFFH',\n",
    "    'FFFFFFHFFFFFFFFFHHFF',\n",
    "    'HFFHFFFHHFHFFFHHFFFF',\n",
    "    'FFFFFFFFFHFHFFHHHFFF',\n",
    "    'HFFFFFHFFFFFHFHFFFFF',\n",
    "    'HFFFFFFFFFFFFFFFHFFH',\n",
    "    'FHFFFFFFFHFFFFFFFFFF',\n",
    "    'FFHFFFFFFFHFFFFHFHFF',\n",
    "    'FFHFHFFFFFFFHHFFFFFG'\n",
    "]\n",
    "\n",
    "\n",
    "class RTDP:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.iterations = 17000\n",
    "        self.gamma = 1.\n",
    "        self.goal_cost = -1.\n",
    "        self.hole_cost = .1\n",
    "        self.default_cost = .1\n",
    "\n",
    "        self.actions = [0, 1, 2, 3]\n",
    "\n",
    "        # FrozenLakeEnv gives us a transition matrix, the states and actions.\n",
    "        # But no costs. So let's set something up ourselves.\n",
    "        self._init_cost()\n",
    "        self.calc_policy()\n",
    "\n",
    "    def calc_policy(self):\n",
    "        # RTDP\n",
    "        V = defaultdict(lambda: 0.)\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "            if i % 500 == 0:\n",
    "                print(i)\n",
    "            obs = self.env.reset()\n",
    "            while True:\n",
    "                action = np.argmin(\n",
    "                    [\n",
    "                        self.cost[obs][a] + self.gamma * sum(\n",
    "                            item[0] * V[item[1]]\n",
    "                            for item in self.env.P[obs][a]\n",
    "                        )\n",
    "                        for a in self.actions\n",
    "                    ]\n",
    "                )\n",
    "                V[obs] = self.cost[obs][action] + self.gamma * sum(\n",
    "                    item[0] * V[item[1]]\n",
    "                    for item in self.env.P[obs][action]\n",
    "                )\n",
    "                obs, reward, done, _ = self.env.step(action)\n",
    "                if done:\n",
    "                    cost_ = -1\n",
    "                    if reward == 0.0:\n",
    "                        cost_ = 1\n",
    "                    V[obs] = cost_ + self.gamma * sum(\n",
    "                        item[0] * V[item[1]]\n",
    "                        for item in self.env.P[obs][action]\n",
    "                    )\n",
    "                    break\n",
    "\n",
    "        print(' ')\n",
    "        print(V)\n",
    "        self.V = V\n",
    "\n",
    "    def _init_cost(self):\n",
    "        # TODO Code below kinda ugly.\n",
    "        cost = defaultdict(dict)\n",
    "        for state in range(self.env.observation_space.n):\n",
    "            for action in self.actions:\n",
    "                # why 1? its the action itself. Others are slippery outcomes.\n",
    "                if len(self.env.P[state][action]) == 1:\n",
    "                    if self.env.P[state][action][0][2] == 1.0:\n",
    "                        cost[state][action] = self.goal_cost\n",
    "                    else:\n",
    "                        cost[state][action] = self.hole_cost\n",
    "                    continue\n",
    "\n",
    "                done = self.env.P[state][action][1][3]\n",
    "                if done and self.env.P[state][action][1][2] == 0.0:\n",
    "                    cost[state][action] = self.hole_cost\n",
    "                else:\n",
    "                    cost[state][action] = self.default_cost\n",
    "\n",
    "                if done and self.env.P[state][action][1][2] == 1.0:\n",
    "                    cost[state][action] = self.goal_cost\n",
    "\n",
    "        self.cost = cost\n",
    "\n",
    "    def policy(self, state):\n",
    "        return np.argmin(\n",
    "            [\n",
    "                self.cost[state][a] + self.gamma * sum(\n",
    "                    item[0] * self.V[item[1]]\n",
    "                    for item in self.env.P[state][a]\n",
    "                )\n",
    "                for a in self.actions\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "def evaluate(rtdp, env):\n",
    "    rewards = 0.\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "    while not done:\n",
    "        state, reward, done, _ = env.step(rtdp.policy(state))\n",
    "        rewards += reward\n",
    "        steps += 1\n",
    "        if steps > 1e4:\n",
    "            break\n",
    "\n",
    "    return rewards\n",
    "\n",
    "\n",
    "def run():\n",
    "    env = FrozenLakeEnv(desc=MAP_20x20)\n",
    "    rtdp = RTDP(env)\n",
    "    tot_rewards = 0.\n",
    "    eval_iter = int(1e4)\n",
    "    for i in range(eval_iter):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        tot_rewards += evaluate(rtdp, env)\n",
    "    print(tot_rewards / eval_iter)\n",
    "\n",
    "\n",
    "run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value function:\n",
      "[0.54201404 0.49878743 0.47067727 0.45683193 0.5584404  0.\n",
      " 0.35834012 0.         0.59179013 0.64307363 0.61520214 0.\n",
      " 0.         0.74171617 0.86283528 0.        ]\n",
      "Optimal policy:\n",
      "[0 3 3 3 0 0 0 0 3 1 0 0 0 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Simple Example of Real Time Dynamic Programming (RTDP) with value iteration algorithm and policy\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "# Create FrozenLake environment\n",
    "env = gym.make('FrozenLake-v1')\n",
    "\n",
    "# Set hyperparameters\n",
    "gamma = 0.99\n",
    "theta = 1e-6\n",
    "\n",
    "# Initialize value function V with zeros\n",
    "V = np.zeros(env.observation_space.n)\n",
    "\n",
    "# Value Iteration algorithm\n",
    "while True:\n",
    "    delta = 0\n",
    "    for s in range(env.observation_space.n):\n",
    "        v = V[s]\n",
    "        # Calculate value for each action in the current state\n",
    "        q_values = np.zeros(env.action_space.n)\n",
    "        for a in range(env.action_space.n):\n",
    "            for p, s_next, r, done in env.P[s][a]:\n",
    "                q_values[a] += p * (r + gamma * V[s_next])\n",
    "        # Update value function for the current state\n",
    "        V[s] = np.max(q_values)\n",
    "        delta = max(delta, abs(v - V[s]))\n",
    "    if delta < theta:\n",
    "        break\n",
    "\n",
    "# Print optimal value function\n",
    "print(\"Optimal value function:\")\n",
    "print(V)\n",
    "\n",
    "# Print optimal policy\n",
    "policy = np.zeros(env.observation_space.n, dtype=int)\n",
    "for s in range(env.observation_space.n):\n",
    "    q_values = np.zeros(env.action_space.n)\n",
    "    for a in range(env.action_space.n):\n",
    "        for p, s_next, r, done in env.P[s][a]:\n",
    "            q_values[a] += p * (r + gamma * V[s_next])\n",
    "    policy[s] = np.argmax(q_values)\n",
    "print(\"Optimal policy:\")\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06848032 0.06111567 0.07422254 0.05560469 0.09153995 0.\n",
      " 0.11212558 0.         0.14522151 0.24737863 0.29954442 0.\n",
      " 0.         0.37986011 0.63898452 0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Second Example of RTDP\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('FrozenLake-v1')\n",
    "\n",
    "def rtdp(env, gamma=0.9, theta=0.0001):\n",
    "    V = np.zeros(env.observation_space.n)\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in range(env.observation_space.n):\n",
    "            v = V[s]\n",
    "            q_values = np.zeros(env.action_space.n)\n",
    "            for a in range(env.action_space.n):\n",
    "                for prob, next_state, reward, done in env.P[s][a]:\n",
    "                    q_values[a] += prob * (reward + gamma * V[next_state])\n",
    "            V[s] = np.max(q_values)\n",
    "            delta = max(delta, abs(v - V[s]))\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return V\n",
    "\n",
    "optimal_value_function = rtdp(env)\n",
    "print(optimal_value_function)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
